# Schduler

در Kubernetes، Scheduler (برنامه‌ریز) یکی از اجزای اصلی Control Plane است. وظیفه Scheduler مدیریت فرآیند تخصیص (Scheduling) پادها به نودها در کلاستر را بر عهده دارد. عنصر Scheduler به صورت مداوم کلیه‌ی پادهای درخواستی که باید در کلاستر اجرا شوند را بررسی کرده و آن‌ها را به یک نود مناسب تخصیص می‌دهد.

وظیفه اصلی Scheduler عبارتند از:

**تخصیص پادها به نودها:** Scheduler بر اساس قوانین و استراتژی‌های تخصیص تعیین شده توسط کاربر یا پیش‌فرض، تصمیم می‌گیرد که هر پاد به کدام نود اختصاص یابد.

**مدیریت منابع:** Scheduler هوشمندانه با استفاده از اطلاعات منابع هر نود و پادها، تصمیم‌گیری می‌کند تا تراز توزیع منابع در کلاستر بهینه باشد.

**استراتژی‌های تخصیص پیشرفته:** Scheduler امکاناتی برای تعیین اولویت‌ها، تحمل خطا، و سایر استراتژی‌های پیشرفته را فراهم کرده است.

**مدیریت وضعیت پادها:** Scheduler وضعیت پادها را پیگیری کرده و در صورت نیاز به تغییر تخصیص منابع یا راه‌اندازی مجدد پادها تصمیم می‌گیرد.

**قابلیت گسترش:** Scheduler به صورت افزونه‌پذیر است، به این معنا که می‌توانید استراتژی‌های خاص خود را برای تخصیص پادها به نودها اضافه کنید.

به طور کلی، Scheduler به کنترل کاربری تخصیص منابع و مدیریت بار کلاستر کمک می‌کند و از توزیع موثر پادها بین نودها اطمینان حاصل می‌کند.

# مواردی که در تخصیص پار به نود ها مورد بررسی قرار میگیرند عبارتند از : 
![image](https://github.com/milad6745/Kubernetes/assets/113288076/cad5a273-81de-4177-a29f-3d6834c7dde3)

حالا اگر schduer امامن را از کار بیاندازیم و یک پاد را delete کینم میبینیم که پاد جدید بالا میاید اما در مرحله pending باقی میماند
```bash
coredns-565d847f94-4rn6n                              0/1     Pending   0              11s
coredns-565d847f94-j624g                              1/1     Running   0              125m
coredns-565d847f94-nm58l                              1/1     Running   0              2d1h
coredns-565d847f94-xrp5n                              1/1     Running   0              130m
```
برای این منظور است که schduler وقتی از کار میافتد پاد به نود تخصیص داده نمیشود .


## ّFiltering And Scoring

فیلترینگ (Filtering) و اسکورینگ (Scoring) در کوبرنتیز بخشی از فرایند زمان‌بندی (Scheduling) هستند که به منظور انتخاب بهترین نود (Node) برای اجرای پادها (Pods) استفاده می‌شوند. این دو مرحله به ترتیب انجام می‌شوند تا یک نود مناسب برای اجرای یک پاد پیدا شود. در ادامه این مراحل را به تفصیل شرح می‌دهم:

### 1. **فیلترینگ (Filtering):**

در این مرحله، کوبرنتیز لیست تمام نودهای موجود را بررسی کرده و تنها آن‌هایی که حداقل الزامات پاد را برآورده می‌کنند، انتخاب می‌کند. نودهایی که معیارهای لازم را ندارند، از لیست حذف می‌شوند.


این مرحله منجر به حذف نودهایی می‌شود که توانایی یا صلاحیت میزبانی پاد را ندارند. اگر پس از فیلترینگ هیچ نودی باقی نماند، پاد در صف انتظار باقی می‌ماند تا زمانی که یک نود مناسب در دسترس قرار گیرد.

### 2. **اسکورینگ (Scoring):**

در این مرحله، نودهای باقی‌مانده از فرایند فیلترینگ، امتیازدهی می‌شوند. هدف از این مرحله، انتخاب بهترین نود از بین نودهای ممکن است.


هر نود بر اساس مجموعه‌ای از این معیارها امتیازدهی می‌شود و نودی که بالاترین امتیاز را کسب کند، برای اجرای پاد انتخاب می‌شود.

### **سفارشی‌سازی فیلترینگ و اسکورینگ:**
در کوبرنتیز، شما می‌توانید با استفاده از `Scheduler Policies` یا استفاده از یک زمان‌بند سفارشی (Custom Scheduler)، قوانین فیلترینگ و اسکورینگ را سفارشی‌سازی کنید.

- **Scheduler Extender:** با استفاده از افزونه‌های زمان‌بندی، می‌توانید فیلترها و اسکورهای خود را به فرایند زمان‌بندی اضافه کنید.
- **Custom Scheduler:** می‌توانید زمان‌بند خاص خود را پیاده‌سازی کرده و آن را در کنار زمان‌بند پیش‌فرض کوبرنتیز استفاده کنید.





عالیه! چون کلاستر Kubernetes شما آماده‌ست و با `kubectl get node` لیست Nodeها رو هم دارید، حالا می‌تونیم بریم سراغ یکی از مهم‌ترین مفاهیم در **Scheduling**: یعنی **Filtering و Scoring**.

این دو مرحله اساس کار **Kube-Scheduler** هستن برای اینکه تصمیم بگیره کدوم Pod روی کدوم Node اجرا بشه.

---

## 🎯 مفهوم Filtering و Scoring در Kube-Scheduler

زمانی که یه Pod قراره اجرا بشه، **Scheduler** دو مرحله اصلی رو طی می‌کنه:

---

### 🧪 1. **Filtering (فیلتر کردن)**

در این مرحله، Scheduler فقط Nodeهایی رو نگه می‌داره که **قابلیت میزبانی** Pod رو دارن. مواردی که بررسی می‌شن:

✅ آیا Node فضای کافی (CPU/Memory) داره؟  
✅ آیا Node taint یا محدودیتی داره که این Pod نتونه روش اجرا بشه؟  
✅ آیا Node با requirementsهای Pod (مثل Node Affinity یا tolerations) سازگاره؟  
✅ آیا Node سالم و آماده (Ready) هست؟

📌 تو خروجی شما، هر ۳ Node وضعیت `Ready` دارن، پس فعلاً همشون تو مرحله Filtering می‌تونن انتخاب بشن.

---

### ⭐ 2. **Scoring (امتیازدهی)**

حالا که لیستی از Nodeهای واجد شرایط داریم، Scheduler به هرکدوم **امتیاز** می‌ده.

- امتیازها بین **0 تا 100** هستن (بسته به الگوریتم‌ها).
- Nodeی که بیشترین امتیاز رو بگیره، برنده می‌شه.

💡 معیارهای رایج Scoring:

| معیار | توضیح |
|-------|-------|
| **Least Requested** | نودی که منابع کمتری مصرف کرده (Load پایین‌تر) |
| **Balanced Resource Allocation** | نودی که تعادل خوبی بین CPU و RAM داره |
| **Node Affinity** | بر اساس برچسب‌هایی که توی Spec. گفتی |
| **Image Locality** | نودی که قبلاً اون Image رو داشته |

---

## 🔧 چطور تستش کنیم توی کلاستر خودت؟

### 1. برچسب‌گذاری روی نودها:
```bash
kubectl label nodes kind-worker disktype=ssd
kubectl label nodes kind-worker2 disktype=hdd
```

### 2. ساخت Pod با Node Affinity:
```yaml
# pod-affinity-example.yaml
apiVersion: v1
kind: Pod
metadata:
  name: affinity-pod
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
  containers:
  - name: nginx
    image: nginx
```

### اجرا:
```bash
kubectl apply -f pod-affinity-example.yaml
```

✅ حالا چون Pod گفته فقط روی Nodeهایی با `disktype=ssd` اجرا بشه، **فقط `kind-worker` در مرحله Filtering می‌مونه**، و چون فقط یک Node مونده، روی همون اجرا می‌شه.

---

### 🔍 بررسی اینکه Pod کجا اجرا شد:
```bash
kubectl get pod -o wide
```

---

## 📚 منابع اختیاری (اگه بخوای بیشتر یاد بگیری):

- [Kubernetes Scheduler Configuration](https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/)
- مشاهده دقیق‌تر لاگ Scheduler:
  ```bash
  kubectl logs -n kube-system -l component=kube-scheduler
  ```

---
